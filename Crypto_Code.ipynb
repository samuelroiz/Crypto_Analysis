{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from census import Census\n",
    "# from config import (census_key, gkey, api_key)\n",
    "from config import (poly_key, nomics_key, exchange_rates_api_key)\n",
    "import gmaps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from scipy.stats import linregress\n",
    "from matplotlib import pyplot as plt\n",
    "import urllib.request\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website url for api_key tools: https://polygon.io/docs/get_v3_reference_tickers_anchor\n",
    "# https://github.com/polygon-io/client-python example\n",
    "\n",
    "# url = f\"https://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2020-06-01/2020-06-17?\n",
    "# query_url = url + \"apiKey=\" + poly_key + \"&q=\" + city\n",
    "\n",
    "# # Get polygon data\n",
    "# weather_response = requests.get(query_url)\n",
    "# weather_json = weather_response.json()\n",
    "\n",
    "# # Get the crypto from the response\n",
    "# print(f\"The crypto API responded with: {weather_json}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### History Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_history_example = f\"https://api.nomics.com/v1/market-cap/history?key={nomics_key}&start=2018-04-14T00%3A00%3A00Z&end=2018-05-14T00%3A00%3A00Z\"\n",
    "url_history_2021 = f\"https://api.nomics.com/v1/market-cap/history?key={nomics_key}&start=2020-01-01T00%3A00%3A00Z&end=2020-02-01T00%3A00%3A00Z\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandemic Data History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2021-10-31\"\n",
    "pandemic_url_history = f\"https://api.nomics.com/v1/market-cap/history?key={nomics_key}&start={start_date}T00%3A00%3A00Z&end={end_date}T00%3A00%3A00Z\"\n",
    "\n",
    "# text file to hold the data\n",
    "pandemic_all_data_file = open('pandemic_all_data_file.txt', 'w')\n",
    "pandemic_timestamp_file = open('pandemic_timestamp_file.txt', 'w')\n",
    "pandemic_market_cap_file = open('pandemic_market_cap_file.txt', 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# link for history\n",
    "pandemic_url_history\n",
    "\n",
    "# recieve link and convert raw data to json\n",
    "response = requests.get(pandemic_url_history).json()\n",
    "\n",
    "# find out how many dicts are in the list\n",
    "number_of_dicts = len(response)\n",
    "print(number_of_dicts)\n",
    "\n",
    "# lists of list\n",
    "pandemic_timestamp = []\n",
    "pandemic_market_cap = []\n",
    "\n",
    "# we want to go each list... since we are doing by numbers, we will do the range of 0 to the amount in the url\n",
    "number_of_dicts = list(range(0, number_of_dicts))\n",
    "\n",
    "# for loop: x is going to become number_of_dicts each time...0, once it goes through the code then x changes to 1, repeat etc.\n",
    "for x in number_of_dicts:\n",
    "    timestamp_string = response[x]['timestamp']\n",
    "    new_timestamp_String = timestamp_string.replace('T00:00:00Z', '')\n",
    "    pandemic_timestamp.append(new_timestamp_String)\n",
    "    \n",
    "    \n",
    "    pandemic_market_cap.append(response[x]['market_cap'])\n",
    "    market_cap_string = response[x]['market_cap']\n",
    "\n",
    "    pandemic_all_data_file.write(f\"{new_timestamp_String}, {market_cap_string}\\n\")\n",
    "    pandemic_timestamp_file.write(f\"{new_timestamp_String}\\n\")\n",
    "    pandemic_market_cap_file.write(f\"{market_cap_string}\\n\")\n",
    "\n",
    "pandemic_all_data_file.close()\n",
    "pandemic_timestamp_file.close()\n",
    "pandemic_market_cap_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-01-01'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandemic_timestamp\n",
    "\n",
    "#You can remove a word from a string using str.replace ()\n",
    "myString = response[0]['timestamp']\n",
    "newString = myString.replace('T00:00:00Z', '')\n",
    "newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall of the whole Market from start to Oct. 31st 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2021-10-31\"\n",
    "all_years_url_history = f\"https://api.nomics.com/v1/market-cap/history?key={nomics_key}&start={start_date}T00%3A00%3A00Z&end={end_date}T00%3A00%3A00Z\"\n",
    "\n",
    "# text file to hold the data\n",
    "all_years_all_data_file = open('all_years_all_data_file.txt', 'w')\n",
    "all_years_timestamp_file = open('all_years_timestamp_file.txt', 'w')\n",
    "all_years_market_cap_file = open('all_years_market_cap_file.txt', 'w')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3701\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# link for history\n",
    "all_years_url_history\n",
    "\n",
    "# recieve link and convert raw data to json\n",
    "response = requests.get(all_years_url_history).json()\n",
    "\n",
    "# find out how many dicts are in the list\n",
    "number_of_dicts = len(response)\n",
    "print(number_of_dicts)\n",
    "\n",
    "# lists of list\n",
    "all_years_timestamp = []\n",
    "all_years_market_cap = []\n",
    "\n",
    "# we want to go each list... since we are doing by numbers, we will do the range of 0 to the amount in the url\n",
    "number_of_dicts = list(range(0, number_of_dicts))\n",
    "\n",
    "# for loop: x is going to become number_of_dicts each time...0, once it goes through the code then x changes to 1, repeat etc.\n",
    "for x in number_of_dicts:\n",
    "    all_years_string = response[x]['timestamp']\n",
    "    new_timestamp_String = all_years_string.replace('T00:00:00Z', '')\n",
    "    all_years_timestamp.append(new_timestamp_String)\n",
    "    \n",
    "    \n",
    "    all_years_market_cap.append(response[x]['market_cap'])\n",
    "    market_cap_string = response[x]['market_cap']\n",
    "\n",
    "    all_years_all_data_file.write(f\"{new_timestamp_String}, {market_cap_string}\\n\")\n",
    "    all_years_timestamp_file.write(f\"{new_timestamp_String}\\n\")\n",
    "    all_years_market_cap_file.write(f\"{market_cap_string}\\n\")\n",
    "\n",
    "all_years_all_data_file.close()\n",
    "all_years_timestamp_file.close()\n",
    "all_years_market_cap_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EURO CONVERT BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2021-10-31\"\n",
    "pandemic_url_history = f\"https://api.nomics.com/v1/market-cap/history?key={nomics_key}&start={start_date}T00%3A00%3A00Z&end={end_date}T00%3A00%3A00Z&convert=EUR\"\n",
    "\n",
    "# text file to hold the data\n",
    "pandemic_all_data_file = open('euro_pandemic_all_data_file.txt', 'w')\n",
    "pandemic_timestamp_file = open('euro_pandemic_timestamp_file.txt', 'w')\n",
    "pandemic_market_cap_file = open('euro_pandemic_market_cap_file.txt', 'w')\n",
    "\n",
    "pandemic_all_data_cvs = open('euro_pandemic_all_data_cvs.cvs', 'w')\n",
    "pandemic_timestamp_cvs = open('euro_pandemic_timestamp_cvs.cvs', 'w')\n",
    "pandemic_market_cap_cvs = open('euro_pandemic_market_cap_cvs.cvs', 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# link for history\n",
    "pandemic_url_history\n",
    "\n",
    "# recieve link and convert raw data to json\n",
    "response = requests.get(pandemic_url_history).json()\n",
    "\n",
    "# find out how many dicts are in the list\n",
    "number_of_dicts = len(response)\n",
    "print(number_of_dicts)\n",
    "\n",
    "# lists of list\n",
    "pandemic_timestamp = []\n",
    "pandemic_market_cap = []\n",
    "\n",
    "# we want to go each list... since we are doing by numbers, we will do the range of 0 to the amount in the url\n",
    "number_of_dicts = list(range(0, number_of_dicts))\n",
    "\n",
    "# for loop: x is going to become number_of_dicts each time...0, once it goes through the code then x changes to 1, repeat etc.\n",
    "for x in number_of_dicts:\n",
    "    timestamp_string = response[x]['timestamp']\n",
    "    new_timestamp_String = timestamp_string.replace('T00:00:00Z', '')\n",
    "    pandemic_timestamp.append(new_timestamp_String)\n",
    "    \n",
    "    \n",
    "    pandemic_market_cap.append(response[x]['market_cap'])\n",
    "    market_cap_string = response[x]['market_cap']\n",
    "\n",
    "    pandemic_all_data_file.write(f\"{new_timestamp_String}, {market_cap_string}\\n\")\n",
    "    pandemic_timestamp_file.write(f\"{new_timestamp_String}\\n\")\n",
    "    pandemic_market_cap_file.write(f\"{market_cap_string}\\n\")\n",
    "\n",
    "    pandemic_all_data_cvs.write(f\"{new_timestamp_String}, {market_cap_string}\\n\")\n",
    "    pandemic_timestamp_cvs.write(f\"{new_timestamp_String}\\n\")\n",
    "    pandemic_market_cap_cvs.write(f\"{market_cap_string}\\n\")\n",
    "\n",
    "pandemic_all_data_file.close()\n",
    "pandemic_timestamp_file.close()\n",
    "pandemic_market_cap_file.close()\n",
    "\n",
    "pandemic_all_data_cvs.close()\n",
    "pandemic_timestamp_cvs.close()\n",
    "pandemic_market_cap_cvs.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JAN 2020 to OCT 31st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2021-10-31\"\n",
    "all_years_url_history = f\"https://api.nomics.com/v1/market-cap/history?key={nomics_key}&convert=EUR&start={start_date}T00%3A00%3A00Z&end={end_date}T00%3A00%3A00Z\"\n",
    "\n",
    "# text file to hold the data\n",
    "all_years_all_data_file = open('euro_all_years_all_data_file.txt', 'w')\n",
    "all_years_timestamp_file = open('euro_all_years_timestamp_file.txt', 'w')\n",
    "all_years_market_cap_file = open('euro_all_years_market_cap_file.txt', 'w')\n",
    "\n",
    "all_years_all_data_cvs = open('euro_all_years_all_data_cvs.cvs', 'w')\n",
    "all_years_timestamp_cvs = open('euro_all_years_timestamp_cvs.cvs', 'w')\n",
    "all_years_market_cap_cvs = open('euro_all_years_market_cap_cvs.cvs', 'w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3701\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# link for history\n",
    "all_years_url_history\n",
    "\n",
    "# recieve link and convert raw data to json\n",
    "response = requests.get(all_years_url_history).json()\n",
    "\n",
    "# find out how many dicts are in the list\n",
    "number_of_dicts = len(response)\n",
    "print(number_of_dicts)\n",
    "\n",
    "# lists of list\n",
    "all_years_timestamp = []\n",
    "all_years_market_cap = []\n",
    "\n",
    "# we want to go each list... since we are doing by numbers, we will do the range of 0 to the amount in the url\n",
    "number_of_dicts = list(range(0, number_of_dicts))\n",
    "\n",
    "# for loop: x is going to become number_of_dicts each time...0, once it goes through the code then x changes to 1, repeat etc.\n",
    "for x in number_of_dicts:\n",
    "    all_years_string = response[x]['timestamp']\n",
    "    new_timestamp_String = all_years_string.replace('T00:00:00Z', '')\n",
    "    all_years_timestamp.append(new_timestamp_String)\n",
    "    \n",
    "    \n",
    "    all_years_market_cap.append(response[x]['market_cap'])\n",
    "    market_cap_string = response[x]['market_cap']\n",
    "\n",
    "    all_years_all_data_file.write(f\"{new_timestamp_String}, {market_cap_string}\\n\")\n",
    "    all_years_timestamp_file.write(f\"{new_timestamp_String}\\n\")\n",
    "    all_years_market_cap_file.write(f\"{market_cap_string}\\n\")\n",
    "\n",
    "    all_years_all_data_cvs.write(f\"{new_timestamp_String}, {market_cap_string}\\n\")\n",
    "    all_years_timestamp_cvs.write(f\"{new_timestamp_String}\\n\")\n",
    "    all_years_market_cap_cvs.write(f\"{market_cap_string}\\n\")\n",
    "\n",
    "all_years_all_data_file.close()\n",
    "all_years_timestamp_file.close()\n",
    "all_years_market_cap_file.close()\n",
    "\n",
    "all_years_all_data_cvs.close()\n",
    "all_years_timestamp_cvs.close()\n",
    "all_years_market_cap_cvs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Market Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_3 = f\"https://api.nomics.com/v1/markets?key={nomics_key}\"\n",
    "url_4 = f\"https://api.nomics.com/v1/markets?key={nomics_key}&quote-currency=USD&convert=USD&per-page=100&page=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Currencies Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website url for api_key tools: https://nomics.com/docs/\n",
    "# steps for help: https://github.com/TaylorFacen/nomics-python\n",
    "# Currencie Codes: https://nomics.com/docs/#operation/getCurrenciesTicker\n",
    "\n",
    "url = f\"https://api.nomics.com/v1/?key={nomics_key}\"\n",
    "url_2 = f\"https://api.nomics.com/v1/currencies/ticker?key={nomics_key}&ids=BTC,ETH,XRP,REN&interval=1d,30d&convert=EUR&per-page=100&page=1\"\n",
    "\n",
    "url = f\"https://api.nomics.com/v1/currencies/ticker?key={nomics_key}&ids=BTC\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link's Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -  -  -  -  -  -  -  -  -  - \n",
      "Url's are below...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\" - \" * 10)\n",
    "print(\"Url's are below...\")\n",
    "# print(\"\")\n",
    "# print(f\"https://api.nomics.com/v1/currencies/ticker?key={nomics_key}&ids=BTC,ETH,XRP&interval=1d,30d&convert=EUR&per-page=100&page=1\")\n",
    "# print(\"\")\n",
    "# print(f\"Here is a link of the full market of nomics: https://api.nomics.com/v1/markets?key={nomics_key}\")\n",
    "# print(\"\")\n",
    "# print(f'Here is a link of the market of Converted US, Active nomics: https://api.nomics.com/v1/markets?key={nomics_key}&convert=USD&\"active\"&per-page=10')\n",
    "# print(\"\")\n",
    "# print(f'Here is a link of the History example nomics: https://api.nomics.com/v1/market-cap/history?key={nomics_key}&start=2018-04-14T00%3A00%3A00Z&end=2018-05-14T00%3A00%3A00Z')\n",
    "# print(\"\")\n",
    "# print(f'Here is a link of the History example nomics: https://api.nomics.com/v1/market-cap/history?key={nomics_key}&start=2020-01-01T00%3A00%3A00Z&end=2020-02-01T00%3A00%3A00Z')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(urllib.request.urlopen(url_2).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(urllib.request.urlopen(url_4).read(2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange Rates API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_help = 'https://manage.exchangeratesapi.io/quickstart'\n",
    "url_exchange_rates = 'http://api.exchangeratesapi.io/v1/'\n",
    "\n",
    "url_history_example = f'http://api.exchangeratesapi.io/v1/2013-03-16?access_key={exchange_rates_api_key}&symbols=USD,AUD,CAD,PLN,MXN&format=1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://api.exchangeratesapi.io/v1/2020-01-02?access_key=179e1f444c53dc41dbf7e309e00226fd&symbols=USD,EUR,JPY,GBP,AUD,CAD,CHF,SEK,PLN,MXN,VES,IRR,VND,IDR,UZS,SLL,GNF,LAK,PYG,KHR,STD,BYR,COP&format=1'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dollar_trend_2020_01_01 = f'http://api.exchangeratesapi.io/v1/2020-01-01?access_key={exchange_rates_api_key}&symbols=USD,EUR,JPY,GBP,AUD,CAD,CHF,SEK,PLN,MXN,VES,IRR,VND,IDR,UZS,SLL,GNF,LAK,PYG,KHR,STD,BYR,COP&format=1'\n",
    "dollar_trend_2020_01_02 = f'http://api.exchangeratesapi.io/v1/2020-01-02?access_key={exchange_rates_api_key}&symbols=USD,EUR,JPY,GBP,AUD,CAD,CHF,SEK,PLN,MXN,VES,IRR,VND,IDR,UZS,SLL,GNF,LAK,PYG,KHR,STD,BYR,COP&format=1'\n",
    "\n",
    "# MOST COMMON: USD, EUR, JPY, GBP, AUD, CAD, CHF, SEK \n",
    "# LEAST COMMON: VES, IRR, VND, IDR, UZS, SLL, GNF, LAK, PYG, KHR, STD, BYR, COP\n",
    "# info on least common money used https://fxssi.com/top-10-of-the-weakest-world-currencies-in-current-year\n",
    "# info on most common money used https://fxssi.com/top-5-most-traded-currencies-in-the-world\n",
    "# dollar_trend_2020_01_01\n",
    "dollar_trend_2020_01_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.117088]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USD_rate = []\n",
    "response = requests.get(dollar_trend_2020_01_02).json()\n",
    "response['rates']['USD']\n",
    "USD_rate.append(response['rates']['USD'])\n",
    "USD_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dollar Trend Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://api.exchangeratesapi.io/v1/timeseries\n",
    "\n",
    "#     ? access_key = YOUR_ACCESS_KEY\n",
    "#     & start_date = YYYY-MM-DD\n",
    "#     & end_date = YYYY-MM-DD\n",
    "#     & base = EUR\n",
    "#     & symbols = USD,AUD,CAD,PLN,MXN\n",
    "\n",
    "exch_rates_year_2020_2021 = f'http://api.exchangeratesapi.io/v1/timeseries?access_key={exchange_rates_api_key}&start_date=2020-01-01&end_date=2021-10-31&base=USD'\n",
    "# cannot use... need to pay for time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text file to hold the data\n",
    "dollar_trend_pandemic_rates_file = open('dollar_trend_pandemic_rates_file.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE IS IN EURO'S FOR THIS API\n",
    "# link for history\n",
    "# exch_rates_year_2020_2021\n",
    "date_list = []\n",
    "# lists of list\n",
    "exch_rates_year_2020_2021_rates = []\n",
    "exch_rates_year_2020_2021 = []\n",
    "USD_rate = []\n",
    "EUR_rate = []\n",
    "JPY_rate = []\n",
    "GBP_rate = []\n",
    "AUD_rate = []\n",
    "CHF_rate = []\n",
    "SEK_rate = []\n",
    "PLN_rate = []\n",
    "MXN_rate = []\n",
    "# VES_rate = []\n",
    "IRR_rate = []\n",
    "VND_rate = []\n",
    "IDR_rate = []\n",
    "UZS_rate = []\n",
    "SLL_rate = []\n",
    "GNF_rate = []\n",
    "LAK_rate = []\n",
    "PYG_rate = []\n",
    "KHR_rate = []\n",
    "STD_rate = []\n",
    "BYR_rate = []\n",
    "COP_rate = []\n",
    "\n",
    "date1 = datetime.date(2020, 1, 1)\n",
    "date2 = datetime.date(2021, 10, 31)\n",
    "day = datetime.timedelta(days=1)\n",
    "\n",
    "while date1 <= date2:\n",
    "    date_list.append(date1.strftime('%Y-%m-%d'))\n",
    "    date1 = date1 + day\n",
    "\n",
    "\n",
    "for date in date_list:\n",
    "    exch_rates = f'http://api.exchangeratesapi.io/v1/{date}?access_key={exchange_rates_api_key}&symbols=USD,EUR,JPY,GBP,AUD,CAD,CHF,SEK,PLN,MXN,VES,IRR,VND,IDR,UZS,SLL,GNF,LAK,PYG,KHR,STD,BYR,COP&format=1'\n",
    "\n",
    "    response = requests.get(exch_rates).json()\n",
    "    \n",
    "    USD_rate.append(response['rates']['USD'])\n",
    "    USD_rate_string = response['rates']['USD']\n",
    "\n",
    "    EUR_rate.append(response['rates']['EUR'])\n",
    "    EUR_rate_string = response['rates']['EUR']\n",
    "\n",
    "    JPY_rate.append(response['rates']['JPY'])\n",
    "    JPY_rate_string = response['rates']['JPY']\n",
    "\n",
    "    GBP_rate.append(response['rates']['GBP'])\n",
    "    GBP_rate_string = response['rates']['GBP']\n",
    "\n",
    "    AUD_rate.append(response['rates']['AUD'])\n",
    "    AUD_rate_string = response['rates']['AUD']\n",
    "\n",
    "\n",
    "    CHF_rate.append(response['rates']['CHF'])\n",
    "    CHF_rate_string = response['rates']['CHF']\n",
    "\n",
    "    SEK_rate.append(response['rates']['SEK'])\n",
    "    SEK_rate_string = response['rates']['SEK']\n",
    "\n",
    "    PLN_rate.append(response['rates']['PLN'])\n",
    "    PLN_rate_string = response['rates']['PLN']\n",
    "\n",
    "    MXN_rate.append(response['rates']['MXN'])\n",
    "    MXN_rate_string = response['rates']['MXN']\n",
    "\n",
    "    # VES_rate.append(response['rates']['VES'])\n",
    "    # VES_rate_string = response['rates']['VES']\n",
    "\n",
    "    IRR_rate.append(response['rates']['IRR'])\n",
    "    IRR_rate_string = response['rates']['IRR']\n",
    "\n",
    "    VND_rate.append(response['rates']['VND'])\n",
    "    VND_rate_string = response['rates']['VND']\n",
    "\n",
    "    IDR_rate.append(response['rates']['IDR'])\n",
    "    IDR_rate_string = response['rates']['IDR']\n",
    "\n",
    "    UZS_rate.append(response['rates']['UZS'])\n",
    "    UZS_rate_string = response['rates']['UZS']\n",
    "\n",
    "    SLL_rate.append(response['rates']['SLL'])\n",
    "    SLL_rate_string = response['rates']['SLL']\n",
    "\n",
    "    GNF_rate.append(response['rates']['GNF'])\n",
    "    GNF_rate_string = response['rates']['GNF']\n",
    "\n",
    "    LAK_rate.append(response['rates']['LAK'])\n",
    "    LAK_rate_string = response['rates']['LAK']\n",
    "\n",
    "    PYG_rate.append(response['rates']['PYG'])\n",
    "    PYG_rate_string = response['rates']['PYG']\n",
    "\n",
    "    KHR_rate.append(response['rates']['KHR'])\n",
    "    KHR_rate_string = response['rates']['KHR']\n",
    "\n",
    "    STD_rate.append(response['rates']['STD'])\n",
    "    STD_rate_string = response['rates']['STD']\n",
    "\n",
    "    BYR_rate.append(response['rates']['BYR'])\n",
    "    BYR_rate_string = response['rates']['BYR']\n",
    "\n",
    "    COP_rate.append(response['rates']['COP'])\n",
    "    COP_rate_string = response['rates']['COP']\n",
    "\n",
    "\n",
    "    dollar_trend_pandemic_rates_file.write(f\"{USD_rate_string}, {EUR_rate_string}, {JPY_rate_string}, {GBP_rate_string}, {AUD_rate_string}, {CHF_rate_string}, {SEK_rate_string}, {PLN_rate_string}, {MXN_rate_string}, {IRR_rate_string}, {VND_rate_string}, {IDR_rate_string}, {UZS_rate_string}, {SLL_rate_string}, {GNF_rate_string}, {LAK_rate_string}, {PYG_rate_string}, {KHR_rate_string}, {STD_rate_string}, {BYR_rate_string}, {COP_rate_string}\\n\")\n",
    "\n",
    "dollar_trend_pandemic_rates_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54e022fdd03f6a2018709c75554f810e23f9e40ccca3b075875a360adcb05270"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
